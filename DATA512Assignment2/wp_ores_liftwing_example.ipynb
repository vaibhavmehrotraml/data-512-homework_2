{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Requesting ORES scores through LiftWing ML Service API\n",
    "Wikimedia Foundation (WMF) is reworking access to their APIs. It is likely in the coming years that all API access will require some kind of authentication, either through a simple key/token or through some version of OAuth. For now this is still a work in progress. You can follow the progress from their [API portal](https://api.wikimedia.org/wiki/Main_Page). Another on-going change is better control over API services in situations where those services require additional computational resources, beyond simply serving the text of a web page (i.e., the text of an article). Services like ORES that require running an ML model over the text of an article page is an example of a compute intensive API service.\n",
    "\n",
    "Wikimedia is implementing a new Machine Learning (ML) service infrastructure that they call [LiftWing](https://wikitech.wikimedia.org/wiki/Machine_Learning/LiftWing). Given that ORES already has several ML models that have been well used, ORES is the first set of APIs that are being moved to LiftWing.\n",
    "\n",
    "This example illustrates how to generate article quality estimates for article revisions using the LiftWing version of [ORES](https://www.mediawiki.org/wiki/ORES). The [ORES API documentation](https://ores.wikimedia.org) can be accessed from the main ORES page. The [ORES LiftWing documentation](https://wikitech.wikimedia.org/wiki/Machine_Learning/LiftWing/Usage) is very thin ... even thinner than the standard ORES documentation. Further, it is clear that some parameters have been renamed (e.g., \"revid\" in the old ORES API is now \"rev_id\" in the LiftWing ORES API).\n",
    "\n",
    "\n",
    "## License\n",
    "This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.0 - August 15, 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "# These are standard python modules\n",
    "import json, time, urllib.parse\n",
    "#\n",
    "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (60.0/5000.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2023\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "#\n",
    "#    These are used later - defined here so they, at least, have empty values\n",
    "#\n",
    "USERNAME = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your access token\n",
    "\n",
    "You will need a Wikimedia user account to get access to Lift Wing (the ML API service). You can either [create an account or login](https://api.wikimedia.org/w/index.php?title=Special:UserLogin). If you have a Wikipedia user account - you might already have an Wikimedia account. If you are not sure try your Wikipedia username and password to check it. If you do not have a Wikimedia account you will need to create an account that you can use to get an access token.\n",
    "\n",
    "There is [a 'guide' that describes how to get authentication tokens](https://api.wikimedia.org/wiki/Authentication) - but not everything works the way it is described in that documentation. You should review that documentation and then read the rest of this comment.\n",
    "\n",
    "The documentation talks about using a \"dashboard\" for managing authentication tokens. That's a rather generous description for what looks like a simple list of token things. You might have a hard time finding this \"dashboard\". First, on the left hand side of the page, you'll see a column of links. The bottom section is a set of links titled \"Tools\". In that section is a link that says [Special pages](https://api.wikimedia.org/wiki/Special:SpecialPages) which will take you to a list of ... well, special pages. At the very bottom of the \"Special pages\" page is a section titled \"Other special pages\" (scroll all the way to the bottom). The first link in that section is called [API keys](https://api.wikimedia.org/wiki/Special:AppManagement). When you get to the \"API keys\" page you can create a new key.\n",
    "\n",
    "The authentication guide suggests that you should create a server-side app key. This does not seem to work correctly - as yet. It failed on multiple attempts when I attempted to create a server-side app key. BUT, there is an option to create a [Personal API token](https://api.wikimedia.org/wiki/Authentication) that should work for this course and the type of ORES page scoring that you will need to perform.\n",
    "\n",
    "Note, when you create a Personal API token you are granted the three items - a Client ID, a Client secret, and a Access token - you shold save all three of these. When you dismiss the box they are gone. If you lose any one of the tokens you can destroy or deactivate the Personal API token from the dashboard and then create a new one.\n",
    "\n",
    "The value you need to work the code below is the Access token - a very long string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"token_type\":\"Bearer\",\"expires_in\":14400,\"access_token\":\"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiJiM2U2MjRhMjRjMTlkZDA1NDUyOGY2ZWJlYWRiM2Y0NyIsImp0aSI6IjUzYTJiNzRiNzVhNTg2NTRmZGI1ZjQ1ODc0NWE1MzE1MmYwZTZiZjk0Zjg2ZmMzM2I2OGQ1MDQ4MDNlMTcyNWRkY2U4NTM2YmI0NTk5MDU3IiwiaWF0IjoxNjk3NDkwMjY0LjQzMzg3LCJuYmYiOjE2OTc0OTAyNjQuNDMzODc0LCJleHAiOjE2OTc1MDQ2NjQuNDMwMDAyLCJzdWIiOiI3NDAyMDY0NCIsImlzcyI6Imh0dHBzOi8vbWV0YS53aWtpbWVkaWEub3JnIiwicmF0ZWxpbWl0Ijp7InJlcXVlc3RzX3Blcl91bml0Ijo1MDAwLCJ1bml0IjoiSE9VUiJ9LCJzY29wZXMiOlsiYmFzaWMiXX0.f_-SiH-j2zKXpcTiGNBFvPeLQSWOwcRnEe6kBA92BJig4dT-RelgRzwoe5zNygaUAoyxGBQ4MlKIbczWe3lOKOKwBynTXX_AUARBKFXCh84BU1iN73ag6ssXnl1f8n7j45eOGwO4h79vVVljBDUhZPMRaTdReViwuZhx5WdnE3lSlQ1hJ2StDAjuu3TFklwRqStDSBU5IgMLLgr-38t1H6d7fDlUOppNcqmp2QtsWAcGiPAH16-zPcdIDoNJH_E4k31PHScXtRtAzJt95q2xqN_rMXByLsNfyVl3mVr4gkc8eX83yOyHBy62d2IjgFozXo5IqYG0FVMFPBc4QYSqQwfj0CyV2pd6AYFq8smTuQTGPPmRsv_vtJlbTOGh2nSlr2rrd51h5OdFq2pDrNvaG6cx2eFV6JFOM2-Ym4kLVsj7pEmhAidsHvYokJ_dTuGo4bIUIkCgcevybl1KbDSInm2fphmVBqi58oFhi2lxbSFu4QYJh6audBAAbkkK3e4f76e_t0HioSzjHXrF8Zt4GI6XMqJpUFu9X5umkn1o1rDp4y7AvsK70gvkGmvQNdQ3ow9fnr9o9OtVCWn_ExvnRxsK3Y7ltp1Dnn5KmqMkrCtOp6tYM7rFu-xCqXAuf9wRIS4tNJ2U6qsvY718OUw30KESHH2lNbSgV2SxRlIr0xk\"}"
     ]
    }
   ],
   "source": [
    "!curl -X POST -F 'grant_type=client_credentials' \\\n",
    "-F 'client_id=b3e624a24c19dd054528f6ebeadb3f47' \\\n",
    "-F 'client_secret=806d013c007c9934b408e0854871c34dd8eadd51' \\\n",
    "https://meta.wikimedia.org/w/rest.php/oauth2/access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"rest-read-denied\",\"httpCode\":403,\"httpReason\":\"Forbidden\"}"
     ]
    }
   ],
   "source": [
    "!curl -H \"Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiJlMGVmMzUzY2ZjOWM1OWMwZDdiZjc0NTVhNWQyNDNkZiIsImp0aSI6ImIxNmI2M2FiNDRkMTQ3MjZhOGQ5ZDQyZjc3YWNlNjBkNGFiZjljYTk2ZTc2YzlmOTI2ZTczZWZmODYxNGExMGEzOGUzYjU2YjE4Nzk4NDk1IiwiaWF0IjoxNjk3NDkwNDE4LjQ5NTQ0NCwibmJmIjoxNjk3NDkwNDE4LjQ5NTQ0NywiZXhwIjozMzI1NDM5OTIxOC40OTM0Miwic3ViIjoiNzQwMjA2NDQiLCJpc3MiOiJodHRwczovL21ldGEud2lraW1lZGlhLm9yZyIsInJhdGVsaW1pdCI6eyJyZXF1ZXN0c19wZXJfdW5pdCI6NTAwMCwidW5pdCI6IkhPVVIifSwic2NvcGVzIjpbImJhc2ljIl19.pZEZ7m_6WtKK9555jVGdZCFfHbpEY_V3UAcXn7Xd930c6nd-HHwUXAbQw7rMM29WwBhpAjE0KwAfdZ1PkKyo9Yb9kwxVzDgmIEHTBJ7Y2a5A0z7LlVvYizcnbjLKat0gqq1rQoUl7BZhjWLQxpzlxvRr0On4DLPLgO9RXVQIVQpz0k3OJE-fs8kja_Eb9dfhPssnJOwAyNjRvkOd2EACcVEIp-t7rICrzdK86tFKUtGRdw27Als7pFbnMFu5Y9iZrs_FZTtvsjsIc4MqDBpQ8pszwk3hLkJBTe2e4MU-fnnYnIQOPcKZ_GMFFKB6HybaZeBd9iC2DqTnNBCe6VxGLILKq9BqABs1yJr_lwl_Uo3__3GiL5xK09LnrQyA85ZdERUu95wT1zLLbTi-CBSpaPVRMuXmS7LNF2rjHtJ4957Fk2JZXDiyf4g3_YST5lF95gjG7VUC7m2CVbzoJWx_czMgjSdPedQ0-jufDg_z8odZYNKhLMk2qmC_K2sULI67gDiobxGwXszSwsC6vaTeVumqyp6XdyzN5NbtZdC76RbQ8C0iSJJEpxcnUWKVlc1Ezp7mhP9-9qgQc9jMkSwv8VaSrTheznvWH5rE-tlq2JEqncLmj2p8jpZDfCHdRh4PPnhX4iQWOsM847_dQHDA00pbRzHdYazT_PtL2NTn-Pw\" \\\n",
    "https://api.wikimedia.org/core/v1/wikipedia/en/page/Earth/bare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Once you've done the right set up with your Wikimedia account, it should provide you with three different keys, a Client ID,\n",
    "#   a Client secret, and a Access token.\n",
    "#\n",
    "#   In this case I don't want to distribute my keys with the source of the notebook, so I wrote a key manager object that helps\n",
    "#   track all of my API keys - a username and domain name retrieves the key. The key manager hides the keys on disk separate\n",
    "#   from the code. A common code idiom to hide API keys will use code to extract the key from an OS environment variable. \n",
    "#\n",
    "from apikeys.Manager import Manager\n",
    "keyman = Manager()\n",
    "\n",
    "USERNAME = \"dwmc\"\n",
    "key_info = keyman.findRecord(USERNAME,API_ORES_LIFTWING_ENDPOINT)\n",
    "ACCESS_TOKEN = key_info[0]['key']\n",
    "print(key_info[0]['description'])\n",
    "#print(ACCESS_TOKEN)\n",
    "#\n",
    "#   You can specify these as constants for your own use - just don't distribute the notebook without removing your token\n",
    "#\n",
    "#USERNAME = \"<your_wikimedia_username>\"\n",
    "#ACCESS_TOKEN = \"<your_wikimedia_provided_access_token_its_a_really_long_string>\"\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wikimedia Foundation appears to be issuing access tokens that are adhering to the [JWT (JSON Web Token) standard](https://jwt.io/introduction/). There was also some documentation by IBM about the [use of JWT tokens](https://www.ibm.com/docs/en/cics-ts/6.1?topic=cics-json-web-token-jwt) that I found useful. Keep in mind, documentation from IBM is specific to their implementation of the JWT standard. Access tokens are composed of different parts that specify the domain being accessed and rate limits. The little snippet of code below is not required to make ORES requests. It just allows us to see what is in the Wikimedia provided access token that you were issued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding the ACCESS_TOKEN:\n",
      "Looks like the ACCESS_TOKEN is undefined or an empty value\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf2 in position 1: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLooks like the ACCESS_TOKEN is undefined or an empty value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m(ex)\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m token_components \u001b[38;5;241m=\u001b[39m ACCESS_TOKEN\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token_components) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     header \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mbase64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb64decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_components\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     payload \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(base64\u001b[38;5;241m.\u001b[39mb64decode(token_components[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken Header:\u001b[39m\u001b[38;5;124m\"\u001b[39m,json\u001b[38;5;241m.\u001b[39mdumps(header,indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf2 in position 1: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   Decode the Wikimedia JWT Access token\n",
    "#\n",
    "#   NOTE: This is not required to use LiftWing to request ORES scores. This is just being done to satisfy my curiosity.\n",
    "#\n",
    "import base64\n",
    "\n",
    "print(\"Decoding the ACCESS_TOKEN:\")\n",
    "try:\n",
    "    token_components = ACCESS_TOKEN.split(\".\")\n",
    "    if len(token_components) == 3:\n",
    "        header = json.loads(base64.b64decode(token_components[0]).decode())\n",
    "        payload = json.loads(base64.b64decode(token_components[1]).decode())\n",
    "        print(\"Token Header:\",json.dumps(header,indent=4))\n",
    "        print(\"Token Payload:\",json.dumps(payload,indent=4))\n",
    "        #print(\"Token Signature:\",token_components[2])\n",
    "        print(\"Token Signature: <value_suppressed>\")\n",
    "        #\n",
    "        #  One should be able to use public/private keys to actually validate that signature - left as an exercise for later\n",
    "        #\n",
    "    else:\n",
    "        print(f\"The ACCESS_TOKEN appears to be improperly structured. It should have 3 components and it has {len(token_components)}\")\n",
    "except Exception as ex:\n",
    "    print(f\"Looks like the ACCESS_TOKEN is undefined or an empty value\")\n",
    "    raise(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to make the ORES API request\n",
    "\n",
    "The API request will be made using a function to encapsulate call and make access reusable in other notebooks. The procedure is parameterized, relying on the constants above for some important default parameters. The primary assumption is that this function will be used to request data for a set of article revisions. The main parameter is 'article_revid'. One should be able to simply pass in a new article revision id on each call and get back a python dictionary as the result. A valid result will be a dictionary that contains the probabilities that the specific revision is one of six different article quality levels. Generally, quality level with the highest probability score is considered the quality level for the article. This can be tricky when you have two (or more) highly probable quality levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1** - Call the function by passing in three items, revision id, email, and access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiJlMGVmMzUzY2ZjOWM1OWMwZDdiZjc0NTVhNWQyNDNkZiIsImp0aSI6ImIxNmI2M2FiNDRkMTQ3MjZhOGQ5ZDQyZjc3YWNlNjBkNGFiZjljYTk2ZTc2YzlmOTI2ZTczZWZmODYxNGExMGEzOGUzYjU2YjE4Nzk4NDk1IiwiaWF0IjoxNjk3NDkwNDE4LjQ5NTQ0NCwibmJmIjoxNjk3NDkwNDE4LjQ5NTQ0NywiZXhwIjozMzI1NDM5OTIxOC40OTM0Miwic3ViIjoiNzQwMjA2NDQiLCJpc3MiOiJodHRwczovL21ldGEud2lraW1lZGlhLm9yZyIsInJhdGVsaW1pdCI6eyJyZXF1ZXN0c19wZXJfdW5pdCI6NTAwMCwidW5pdCI6IkhPVVIifSwic2NvcGVzIjpbImJhc2ljIl19.pZEZ7m_6WtKK9555jVGdZCFfHbpEY_V3UAcXn7Xd930c6nd-HHwUXAbQw7rMM29WwBhpAjE0KwAfdZ1PkKyo9Yb9kwxVzDgmIEHTBJ7Y2a5A0z7LlVvYizcnbjLKat0gqq1rQoUl7BZhjWLQxpzlxvRr0On4DLPLgO9RXVQIVQpz0k3OJE-fs8kja_Eb9dfhPssnJOwAyNjRvkOd2EACcVEIp-t7rICrzdK86tFKUtGRdw27Als7pFbnMFu5Y9iZrs_FZTtvsjsIc4MqDBpQ8pszwk3hLkJBTe2e4MU-fnnYnIQOPcKZ_GMFFKB6HybaZeBd9iC2DqTnNBCe6VxGLILKq9BqABs1yJr_lwl_Uo3__3GiL5xK09LnrQyA85ZdERUu95wT1zLLbTi-CBSpaPVRMuXmS7LNF2rjHtJ4957Fk2JZXDiyf4g3_YST5lF95gjG7VUC7m2CVbzoJWx_czMgjSdPedQ0-jufDg_z8odZYNKhLMk2qmC_K2sULI67gDiobxGwXszSwsC6vaTeVumqyp6XdyzN5NbtZdC76RbQ8C0iSJJEpxcnUWKVlc1Ezp7mhP9-9qgQc9jMkSwv8VaSrTheznvWH5rE-tlq2JEqncLmj2p8jpZDfCHdRh4PPnhX4iQWOsM847_dQHDA00pbRzHdYazT_PtL2NTn-Pw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting LiftWing ORES scores for 'Bison' with revid: 1085687913\n",
      "{\n",
      "    \"enwiki\": {\n",
      "        \"models\": {\n",
      "            \"articlequality\": {\n",
      "                \"version\": \"0.9.2\"\n",
      "            }\n",
      "        },\n",
      "        \"scores\": {\n",
      "            \"1085687913\": {\n",
      "                \"articlequality\": {\n",
      "                    \"score\": {\n",
      "                        \"prediction\": \"FA\",\n",
      "                        \"probability\": {\n",
      "                            \"B\": 0.07895665991827401,\n",
      "                            \"C\": 0.03728215742560417,\n",
      "                            \"FA\": 0.5629436065906797,\n",
      "                            \"GA\": 0.30547854835374505,\n",
      "                            \"Start\": 0.011061807252218824,\n",
      "                            \"Stub\": 0.00427722045947826\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#   \n",
    "#\n",
    "#   Which article - the key for the article dictionary defined above\n",
    "article_title = \"Bison\"\n",
    "#\n",
    "print(f\"Getting LiftWing ORES scores for '{article_title}' with revid: {ARTICLE_REVISIONS[article_title]:d}\")\n",
    "#\n",
    "#    Make the call, just pass in the article revision ID, email address, and access token\n",
    "score = request_ores_score_per_article(article_revid=ARTICLE_REVISIONS[article_title],\n",
    "                                       email_address=\"vaibhav1@uw.edu\",\n",
    "                                       access_token=ACCESS_TOKEN)\n",
    "#\n",
    "#    Output the result\n",
    "print(json.dumps(score,indent=4))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2** - Call the function by copying and initializing parameter templates and using those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting LiftWing ORES scores for 'Red squirrel' with revid: 1083787665\n",
      "Invalid leading whitespace, reserved character(s), or returncharacter(s) in header value: 'Bearer \\neyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiJiM2U2MjRhMjRjMTlkZDA1NDUyOGY2ZWJlYWRiM2Y0NyIsImp0aSI6IjQxNGJkZDU2MTRjZmM5ZjcwNTMwMzg3YjUxNWIxMTIyZGExYTA4ZjI5OGQ5NmNiMDY0ZWYwNThmMjZlZTE4NmNiNTZkMzFkY2VkZWFlNDJkIiwiaWF0IjoxNjk3NDg3NTA5Ljk5NjcxOCwibmJmIjoxNjk3NDg3NTA5Ljk5NjcyMSwiZXhwIjozMzI1NDM5NjMwOS45OTQyNDcsInN1YiI6Ijc0MDIwNjQ0IiwiaXNzIjoiaHR0cHM6Ly9tZXRhLndpa2ltZWRpYS5vcmciLCJyYXRlbGltaXQiOnsicmVxdWVzdHNfcGVyX3VuaXQiOjUwMDAsInVuaXQiOiJIT1VSIn0sInNjb3BlcyI6WyJiYXNpYyJdfQ.Me-llirH8skrdXveUydIMOlWfOXO-xZ8hdAWsm_9RDwMRErJfs5gsQ_b4BYImjXhz-w85TknQkH0BBvlJedeqnApnWrJCg5mCg6YPQyGe91nh9ZLLm9UQjnNP92wA1xhVN5gmMnA2fQmqjlUiQKeolXiI6sA0iljA2c_WLS3MVkwyD_QqPTLMeXenPKmYSSt_fVPMrIZE6U3B7Nv44eGINUmxoRF3OQn4LxeZTgddCdX3JhaGVOeps74s5sjxANP6iAf9C_tdo0hSvHrGSx-pQxUa8wuGqXEBhe5nCZ3RqbjbdGSPlSxlcYCaDwV4lhQanUaZaudraAEeabim1jqX8dNtV_ayx5hHgHQ40ulUTuNyre4krpt7kIelTr2uzmFh0dLm6cS6TItKdGBveNWBV2O7VYRqPIP8hnsGzgKWVESmc3Nu2DroOZinAOAL9zOvhm3tbGpMxs_nThs8zfSAjD9olMoclYe61peVxn0xaiVqMf3B9__iu-_GS6WZPS2DSSO3iokDxc-jPiqY4lAy2YS38ntcUEAVsO5JwW7rmNRyUObRWIJd-QdkTbm6fWeVlw_gm6GeUcoKB2w5lG3w1ZxRB2TDYqntvq8-6vZQ0XqhVvSXmumunojQDyiM48f4IWsqvJ2bLzpcqReU39Nkdzyrbhu9lKc-cheX8v9ZNs\\n'\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   What article - the key for the article dictionary defined above\n",
    "article_title = \"Red squirrel\"\n",
    "#\n",
    "#   We have to pass in some parameters used for the request header. Create a copy of the template and fill in some fields.\n",
    "hparams = REQUEST_HEADER_PARAMS_TEMPLATE.copy()\n",
    "hparams['email_address'] = \"dwmc@uw.edu\"\n",
    "hparams['access_token'] = ACCESS_TOKEN\n",
    "#\n",
    "#    We can also do this with the request data - although this might not be as useful as with the header params\n",
    "rd = ORES_REQUEST_DATA_TEMPLATE.copy()\n",
    "rd['rev_id'] = ARTICLE_REVISIONS[article_title]\n",
    "#\n",
    "print(f\"Getting LiftWing ORES scores for '{article_title}' with revid: {ARTICLE_REVISIONS[article_title]:d}\")\n",
    "#\n",
    "#    Make the call, just pass in the article revision ID and the header parameters\n",
    "score = request_ores_score_per_article(request_data=rd,\n",
    "                                       header_params=hparams)\n",
    "#\n",
    "#    Output the result\n",
    "print(json.dumps(score,indent=4))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
